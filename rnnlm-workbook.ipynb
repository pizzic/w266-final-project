{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Recurrent Neural Network Language Model\n",
    "\n",
    "This is the \"working notebook\", with skeleton code to load and train your model, as well as run unit tests. See [rnnlm-instructions.ipynb](rnnlm-instructions.ipynb) for the main writeup.\n",
    "\n",
    "Run the cell below to import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rnnlm_test' from 'rnnlm_test.pyc'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, os, re, shutil, sys, time\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.\"))\n",
    "\n",
    "# utils.pretty_print_matrix uses Pandas. Configure float format here.\n",
    "import pandas as pd\n",
    "pd.set_option('float_format', lambda f: \"{0:.04f}\".format(f))\n",
    "\n",
    "# Helper libraries\n",
    "from shared_lib import utils, vocabulary, tf_embed_viz\n",
    "\n",
    "# Your code\n",
    "import rnnlm\n",
    "import rnnlm_test\n",
    "reload(rnnlm)\n",
    "reload(rnnlm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) RNNLM Inputs and Parameters\n",
    "\n",
    "### Answers for Part (a)\n",
    "You can use LaTeX to typeset math, e.g. `$ f(x) = x^2 $` will render as $ f(x) = x^2 $.\n",
    "\n",
    "1. *$tanh(MW+B)$ The number of parameters in the recurrent cell W is $2H x H$ or $2H^2$ + plus the bias terms of size $H$.*\n",
    "2. *The embedding layer is of size $VH$.*\n",
    "3. *To convert from a word from its index representation to its vector representation, we can index the row in the embeddings matrix since the index representation is one-hot.  Inside the recurrent cell, the number of operations is $O(H^2)$. The softmax to calculate $P(w_{t+1})$ for a single target word is $O(HV)$, so the overall operation is $O(H(H+V))$ since to normalize the percentages, it has to compute the logit for all of the words.  So for calculating the probability across all target words in the vocabulary, the number of computations is the same since we have to compute all of the logits for the single target.*\n",
    "4. *With sampled softmax, computing the probability for each word is $O(K)$.  So the softmax for k samples is $O(k*K)$.  So the total computation, including the recurrent term, is $O(H^2 + H*K)$.  With hierarchical softmax, computing the probability for each word is $O(log_2(V))$.  So the softmax for k samples is $O(k*log_2(V))$.  So the total computation, including the recurrent term, is $O(H^2 + k*log(V))$.*\n",
    "5. *The recurrent layer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Implementing the RNNLM\n",
    "\n",
    "In order to better manage the model parameters, we'll implement our RNNLM in the `RNNLM` class in `rnnlm.py`. We've given you a skeleton of starter code for this, but the bulk of the implementation is left to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(rnnlm)\n",
    "\n",
    "TF_GRAPHDIR = \"tf_graph\"\n",
    "\n",
    "# Clear old log directory.\n",
    "shutil.rmtree(TF_GRAPHDIR, ignore_errors=True)\n",
    "\n",
    "lm = rnnlm.RNNLM(V=10000, H=200, num_layers=2)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "lm.BuildSamplerGraph()\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(TF_GRAPHDIR, lm.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above will load your implementation, construct the graph, and write a logdir for TensorBoard. You can bring up TensorBoard with:\n",
    "```\n",
    "cd assignment/a4\n",
    "tensorboard --logdir tf_graph --port 6006\n",
    "```\n",
    "As usual, check http://localhost:6006/ and visit the \"Graphs\" tab to inspect your implementation. Remember, judicious use of `tf.name_scope()` and/or `tf.variable_scope()` will greatly improve the visualization, and make code easier to debug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided a few unit tests below to verify some *very* basic properties of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_shapes_embed (rnnlm_test.TestRNNLMCore) ... ok\n",
      "test_shapes_output (rnnlm_test.TestRNNLMCore) ... ok\n",
      "test_shapes_recurrent (rnnlm_test.TestRNNLMCore) ... ok\n",
      "test_shapes_train (rnnlm_test.TestRNNLMTrain) ... ok\n",
      "test_shapes_sample (rnnlm_test.TestRNNLMSampler) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 1.374s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=5 errors=0 failures=0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "reload(rnnlm_test)\n",
    "\n",
    "testnames = [\"TestRNNLMCore\", \"TestRNNLMTrain\", \"TestRNNLMSampler\"]\n",
    "\n",
    "unittest.TextTestRunner(verbosity=2).run(\n",
    "    unittest.TestLoader().loadTestsFromNames(\n",
    "        testnames, rnnlm_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the error messages are intentionally somewhat spare, and that passing tests are no guarantee of model correctness! Your best chance of success is through careful coding and understanding of how the model works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Training your RNNLM (5 points)\n",
    "\n",
    "We'll give you data loader functions in **`utils.py`**. They work similarly to the loaders in the Week 5 notebook.\n",
    "\n",
    "Particularly, `utils.batch_generator` will return an iterator that yields minibatches in the correct format. Batches will be of size `[batch_size, max_time]`, and consecutive batches will line up along rows so that the final state $h^{\\text{final}}$ of one batch can be used as the initial state $h^{\\text{init}}$ for the next.\n",
    "\n",
    "For example, using a toy corpus:  \n",
    "*(Ignore the ugly formatter code.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Input words w:</h3><table><tr><th>Batch 0</th><th>Batch 1</th></tr><tr><td><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_0</th>\n",
       "      <th>w_1</th>\n",
       "      <th>w_2</th>\n",
       "      <th>w_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>Mary</td>\n",
       "      <td>had</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>The</td>\n",
       "      <td>lamb</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "\n",
       "<script>\n",
       "var df = $('table.dataframe');\n",
       "var cells = df.children('tbody').children('tr')\n",
       "                                .children('td');\n",
       "cells.css(\"width\", \"30px\").css(\"height\", \"30px\");\n",
       "</script></td><td><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_0</th>\n",
       "      <th>w_1</th>\n",
       "      <th>w_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little</td>\n",
       "      <td>lamb</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>as</td>\n",
       "      <td>snow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "\n",
       "<script>\n",
       "var df = $('table.dataframe');\n",
       "var cells = df.children('tbody').children('tr')\n",
       "                                .children('td');\n",
       "cells.css(\"width\", \"30px\").css(\"height\", \"30px\");\n",
       "</script></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Target words y:</h3><table><tr><th>Batch 0</th><th>Batch 1</th></tr><tr><td><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_0</th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mary</td>\n",
       "      <td>had</td>\n",
       "      <td>a</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The</td>\n",
       "      <td>lamb</td>\n",
       "      <td>was</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "\n",
       "<script>\n",
       "var df = $('table.dataframe');\n",
       "var cells = df.children('tbody').children('tr')\n",
       "                                .children('td');\n",
       "cells.css(\"width\", \"30px\").css(\"height\", \"30px\");\n",
       "</script></td><td><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_0</th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lamb</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as</td>\n",
       "      <td>snow</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "\n",
       "<script>\n",
       "var df = $('table.dataframe');\n",
       "var cells = df.children('tbody').children('tr')\n",
       "                                .children('td');\n",
       "cells.css(\"width\", \"30px\").css(\"height\", \"30px\");\n",
       "</script></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toy_corpus = \"<s> Mary had a little lamb . <s> The lamb was white as snow . <s>\"\n",
    "toy_corpus = np.array(toy_corpus.split())\n",
    "\n",
    "html = \"<h3>Input words w:</h3>\"\n",
    "html += \"<table><tr><th>Batch 0</th><th>Batch 1</th></tr><tr>\"\n",
    "bi = utils.batch_generator(toy_corpus, batch_size=2, max_time=4)\n",
    "for i, (w,y) in enumerate(bi):\n",
    "    html += \"<td>\" + utils.render_matrix(w, cols=[\"w_%d\" % d for d in range(w.shape[1])], dtype=object) + \"</td>\"\n",
    "html += \"</tr></table>\"\n",
    "display(HTML(html))\n",
    "\n",
    "html = \"<h3>Target words y:</h3>\"\n",
    "html += \"<table><tr><th>Batch 0</th><th>Batch 1</th></tr><tr>\"\n",
    "bi = utils.batch_generator(toy_corpus, batch_size=2, max_time=4)\n",
    "for i, (w,y) in enumerate(bi):\n",
    "    html += \"<td>\" + utils.render_matrix(y, cols=[\"y_%d\" % d for d in range(y.shape[1])], dtype=object) + \"</td>\"\n",
    "html += \"</tr></table>\"\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data we feed to our model will be word indices, but the shape will be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Implement the `run_epoch` function\n",
    "We've given you some starter code for logging progress; fill this in with actual call(s) to `session.run` with the appropriate arguments to run a training step. \n",
    "\n",
    "Be sure to handle the initial state properly at the beginning of an epoch, and remember to carry over the final state from each batch and use it as the initial state for the next.\n",
    "\n",
    "**Note:** we provide a `train=True` flag to enable train mode. If `train=False`, this function can also be used for scoring the dataset - see `score_dataset()` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(lm, session, batch_iterator,\n",
    "              train=False, verbose=False,\n",
    "              tick_s=10, learning_rate=0.1):\n",
    "    start_time = time.time()\n",
    "    tick_time = start_time  # for showing status\n",
    "    total_cost = 0.0  # total cost, summed over all words\n",
    "    total_batches = 0\n",
    "    total_words = 0\n",
    "\n",
    "    if train:\n",
    "        train_op = lm.train_step_\n",
    "        use_dropout = True\n",
    "        loss = lm.train_loss_\n",
    "    else:\n",
    "        train_op = tf.no_op()\n",
    "        use_dropout = False  # no dropout at test time\n",
    "        loss = lm.loss_  # true loss, if train_loss is an approximation\n",
    "\n",
    "    for i, (w, y) in enumerate(batch_iterator):\n",
    "        cost = 0.0\n",
    "        # At first batch in epoch, get a clean intitial state.\n",
    "        if i == 0:\n",
    "            h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "\n",
    "        #### YOUR CODE HERE ####\n",
    "        feed_dict = { lm.input_w_ : w, lm.target_y_ : y, \n",
    "                     lm.learning_rate_ : learning_rate, \n",
    "                     lm.use_dropout_ : use_dropout }\n",
    "        cost, _ = session.run([loss, train_op], feed_dict=feed_dict)\n",
    "        lm.initial_h_ = lm.final_h_\n",
    "\n",
    "        #### END(YOUR CODE) ####\n",
    "        total_cost += cost\n",
    "        total_batches = i + 1\n",
    "        total_words += w.size  # w.size = batch_size * max_time\n",
    "\n",
    "        ##\n",
    "        # Print average loss-so-far for epoch\n",
    "        # If using train_loss_, this may be an underestimate.\n",
    "        if verbose and (time.time() - tick_time >= tick_s):\n",
    "            avg_cost = total_cost / total_batches\n",
    "            avg_wps = total_words / (time.time() - start_time)\n",
    "            print \"[batch %d]: seen %d words at %d wps, loss = %.3f\" % (\n",
    "                i, total_words, avg_wps, avg_cost)\n",
    "            tick_time = time.time()  # reset time ticker\n",
    "\n",
    "    return total_cost / total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_dataset(lm, session, ids, name=\"Data\"):\n",
    "    # For scoring, we can use larger batches to speed things up.\n",
    "    bi = utils.batch_generator(ids, batch_size=100, max_time=100)\n",
    "    cost = run_epoch(lm, session, bi, \n",
    "                     learning_rate=1.0, train=False, \n",
    "                     verbose=False, tick_s=3600)\n",
    "    print \"%s: avg. loss: %.03f  (perplexity: %.02f)\" % (name, cost, np.exp(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the cell below to verify your implementation of `run_epoch`, and to test your RNN on a (very simple) toy dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_toy_model (rnnlm_test.RunEpochTester) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 155]: seen 7800 words at 7792 wps, loss = 0.922\n",
      "[batch 347]: seen 17400 words at 8681 wps, loss = 0.537\n",
      "[batch 550]: seen 27550 words at 9163 wps, loss = 0.390\n",
      "[batch 756]: seen 37850 words at 9437 wps, loss = 0.313\n",
      "Train set: avg. loss: 0.001  (perplexity: 1.00)\n",
      "Test set: avg. loss: 0.002  (perplexity: 1.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 5.281s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(rnnlm); reload(rnnlm_test)\n",
    "th = rnnlm_test.RunEpochTester(\"test_toy_model\")\n",
    "th.setUp(); th.injectCode(run_epoch, score_dataset)\n",
    "unittest.TextTestRunner(verbosity=2).run(th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as above, this is a *very* simple test case that does not guarantee model correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Run Training\n",
    "\n",
    "We'll give you the outline of the training procedure, but you'll need to fill in a call to your `run_epoch` function. \n",
    "\n",
    "At the end of training, we use a `tf.train.Saver` to save a copy of the model to `./tf_saved/rnnlm_trained`. You'll want to load this from disk to work on later parts of the assignment; see **part (d)** for an example of how this is done.\n",
    "\n",
    "#### Tuning Hyperparameters\n",
    "With a sampled softmax loss, the default hyperparameters should train 5 epochs in around 15 minutes on a single-core GCE instance, and reach a training set perplexity below 200.\n",
    "\n",
    "However, it's possible to do significantly better. Try experimenting with multiple RNN layers (`num_layers` > 1) or a larger hidden state - though you may also need to adjust the learning rate and number of epochs for a larger model.\n",
    "\n",
    "You can also experiment with a larger vocabulary. This will look worse for perplexity, but will be a better model overall as it won't treat so many words as `<unk>`.\n",
    "\n",
    "#### Notes on Speed\n",
    "\n",
    "To speed things up, you may want to re-start your GCE instance with more CPUs. Using a 16-core machine will train *very* quickly if using a sampled softmax lost, almost as fast as a GPU. (Because of the sequential nature of the model, GPUs aren't actually much faster than CPUs for training and running RNNs.) The training code will print the words-per-second processed; with the default settings on a single core, you can expect around 8000 WPS, or up to more than 25000 WPS on a fast multi-core machine.\n",
    "\n",
    "You might also want to modify the code below to only run score_dataset at the very end, after all epochs are completed. This will speed things up significantly, since `score_dataset` uses the full softmax loss - and so often can take longer than a whole training epoch!\n",
    "\n",
    "#### Submitting your model\n",
    "You should submit your trained model along with the assignment. Do:\n",
    "```\n",
    "git add tf_saved/rnnlm_trained tf_saved/rnnlm_trained.meta\n",
    "git commit -m \"Adding trained model.\"\n",
    "```\n",
    "Unless you train a very large model, these files should be < 50 MB and no problem for git to handle. If you do also train a large model, please only submit the smaller one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 57340 sentences (1.16119e+06 tokens)\n",
      "Training set: 45872 sentences (924077 tokens)\n",
      "Test set: 11468 sentences (237115 tokens)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "V = 10000\n",
    "vocab, train_ids, test_ids = utils.load_corpus(\"brown\", split=0.8, V=V, shuffle=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "max_time = 20\n",
    "batch_size = 50\n",
    "learning_rate = 0.2\n",
    "num_epochs = 20\n",
    "\n",
    "# Model parameters\n",
    "model_params = dict(V=vocab.size, \n",
    "                    H=200, \n",
    "                    softmax_ns=200,\n",
    "                    num_layers=3)\n",
    "\n",
    "TF_SAVEDIR = \"tf_saved\"\n",
    "checkpoint_filename = os.path.join(TF_SAVEDIR, \"rnnlm\")\n",
    "trained_filename = os.path.join(TF_SAVEDIR, \"rnnlm_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "[batch 276]: seen 277000 words at 9230 wps, loss = 5.702\n",
      "[batch 549]: seen 550000 words at 9159 wps, loss = 5.327\n",
      "[batch 814]: seen 815000 words at 9048 wps, loss = 5.135\n",
      "[epoch 1] Completed in 0:01:51\n",
      "[epoch 1] [epoch 1] Test set: avg. loss: 5.872  (perplexity: 354.83)\n",
      "\n",
      "[epoch 2] Starting epoch 2\n",
      "[batch 276]: seen 277000 words at 9214 wps, loss = 4.576\n",
      "[batch 562]: seen 563000 words at 9357 wps, loss = 4.551\n",
      "[batch 842]: seen 843000 words at 9339 wps, loss = 4.528\n",
      "[epoch 2] Completed in 0:01:48\n",
      "[epoch 2] [epoch 2] Test set: avg. loss: 5.711  (perplexity: 302.06)\n",
      "\n",
      "[epoch 3] Starting epoch 3\n",
      "[batch 287]: seen 288000 words at 9575 wps, loss = 4.431\n",
      "[batch 567]: seen 568000 words at 9439 wps, loss = 4.422\n",
      "[batch 844]: seen 845000 words at 9369 wps, loss = 4.407\n",
      "[epoch 3] Completed in 0:01:48\n",
      "[epoch 3] [epoch 3] Test set: avg. loss: 5.628  (perplexity: 278.12)\n",
      "\n",
      "[epoch 4] Starting epoch 4\n",
      "[batch 283]: seen 284000 words at 9439 wps, loss = 4.347\n",
      "[batch 569]: seen 570000 words at 9482 wps, loss = 4.341\n",
      "[batch 852]: seen 853000 words at 9458 wps, loss = 4.332\n",
      "[epoch 4] Completed in 0:01:47\n",
      "[epoch 4] [epoch 4] Test set: avg. loss: 5.572  (perplexity: 262.85)\n",
      "\n",
      "[epoch 5] Starting epoch 5\n",
      "[batch 273]: seen 274000 words at 9115 wps, loss = 4.287\n",
      "[batch 552]: seen 553000 words at 9199 wps, loss = 4.284\n",
      "[batch 834]: seen 835000 words at 9264 wps, loss = 4.277\n",
      "[epoch 5] Completed in 0:01:49\n",
      "[epoch 5] [epoch 5] Test set: avg. loss: 5.532  (perplexity: 252.57)\n",
      "\n",
      "[epoch 6] Starting epoch 6\n",
      "[batch 280]: seen 281000 words at 9337 wps, loss = 4.242\n",
      "[batch 559]: seen 560000 words at 9307 wps, loss = 4.241\n",
      "[batch 840]: seen 841000 words at 9325 wps, loss = 4.235\n",
      "[epoch 6] Completed in 0:01:49\n",
      "[epoch 6] [epoch 6] Test set: avg. loss: 5.494  (perplexity: 243.26)\n",
      "\n",
      "[epoch 7] Starting epoch 7\n",
      "[batch 279]: seen 280000 words at 9313 wps, loss = 4.207\n",
      "[batch 562]: seen 563000 words at 9358 wps, loss = 4.206\n",
      "[batch 833]: seen 834000 words at 9249 wps, loss = 4.201\n",
      "[epoch 7] Completed in 0:01:50\n",
      "[epoch 7] [epoch 7] Test set: avg. loss: 5.465  (perplexity: 236.31)\n",
      "\n",
      "[epoch 8] Starting epoch 8\n",
      "[batch 273]: seen 274000 words at 9111 wps, loss = 4.176\n",
      "[batch 554]: seen 555000 words at 9236 wps, loss = 4.177\n",
      "[batch 826]: seen 827000 words at 9171 wps, loss = 4.172\n",
      "[epoch 8] Completed in 0:01:50\n",
      "[epoch 8] [epoch 8] Test set: avg. loss: 5.437  (perplexity: 229.68)\n",
      "\n",
      "[epoch 9] Starting epoch 9\n",
      "[batch 269]: seen 270000 words at 8986 wps, loss = 4.146\n",
      "[batch 543]: seen 544000 words at 9052 wps, loss = 4.147\n",
      "[batch 815]: seen 816000 words at 9052 wps, loss = 4.143\n",
      "[epoch 9] Completed in 0:01:52\n",
      "[epoch 9] [epoch 9] Test set: avg. loss: 5.404  (perplexity: 222.36)\n",
      "\n",
      "[epoch 10] Starting epoch 10\n",
      "[batch 284]: seen 285000 words at 9493 wps, loss = 4.122\n",
      "[batch 552]: seen 553000 words at 9198 wps, loss = 4.121\n",
      "[batch 823]: seen 824000 words at 9139 wps, loss = 4.117\n",
      "[epoch 10] Completed in 0:01:51\n",
      "[epoch 10] [epoch 10] Test set: avg. loss: 5.382  (perplexity: 217.44)\n",
      "\n",
      "[epoch 11] Starting epoch 11\n",
      "[batch 277]: seen 278000 words at 9255 wps, loss = 4.097\n",
      "[batch 555]: seen 556000 words at 9253 wps, loss = 4.098\n",
      "[batch 839]: seen 840000 words at 9315 wps, loss = 4.092\n",
      "[epoch 11] Completed in 0:01:48\n",
      "[epoch 11] [epoch 11] Test set: avg. loss: 5.362  (perplexity: 213.20)\n",
      "\n",
      "[epoch 12] Starting epoch 12\n",
      "[batch 271]: seen 272000 words at 9037 wps, loss = 4.076\n",
      "[batch 554]: seen 555000 words at 9224 wps, loss = 4.077\n",
      "[batch 830]: seen 831000 words at 9209 wps, loss = 4.074\n",
      "[epoch 12] Completed in 0:01:50\n",
      "[epoch 12] [epoch 12] Test set: avg. loss: 5.342  (perplexity: 208.96)\n",
      "\n",
      "[epoch 13] Starting epoch 13\n",
      "[batch 283]: seen 284000 words at 9446 wps, loss = 4.055\n",
      "[batch 564]: seen 565000 words at 9392 wps, loss = 4.057\n",
      "[batch 840]: seen 841000 words at 9317 wps, loss = 4.053\n",
      "[epoch 13] Completed in 0:01:49\n",
      "[epoch 13] [epoch 13] Test set: avg. loss: 5.329  (perplexity: 206.16)\n",
      "\n",
      "[epoch 14] Starting epoch 14\n",
      "[batch 262]: seen 263000 words at 8745 wps, loss = 4.040\n",
      "[batch 538]: seen 539000 words at 8967 wps, loss = 4.040\n",
      "[batch 819]: seen 820000 words at 9088 wps, loss = 4.038\n",
      "[epoch 14] Completed in 0:01:52\n",
      "[epoch 14] [epoch 14] Test set: avg. loss: 5.314  (perplexity: 203.09)\n",
      "\n",
      "[epoch 15] Starting epoch 15\n",
      "[batch 273]: seen 274000 words at 9119 wps, loss = 4.025\n",
      "[batch 551]: seen 552000 words at 9185 wps, loss = 4.026\n",
      "[batch 834]: seen 835000 words at 9266 wps, loss = 4.023\n",
      "[epoch 15] Completed in 0:01:49\n",
      "[epoch 15] [epoch 15] Test set: avg. loss: 5.299  (perplexity: 200.14)\n",
      "\n",
      "[epoch 16] Starting epoch 16\n",
      "[batch 273]: seen 274000 words at 9127 wps, loss = 4.011\n",
      "[batch 551]: seen 552000 words at 9189 wps, loss = 4.013\n",
      "[batch 835]: seen 836000 words at 9273 wps, loss = 4.011\n",
      "[epoch 16] Completed in 0:01:49\n",
      "[epoch 16] [epoch 16] Test set: avg. loss: 5.287  (perplexity: 197.79)\n",
      "\n",
      "[epoch 17] Starting epoch 17\n",
      "[batch 276]: seen 277000 words at 9231 wps, loss = 3.998\n",
      "[batch 552]: seen 553000 words at 9204 wps, loss = 3.999\n",
      "[batch 835]: seen 836000 words at 9270 wps, loss = 3.997\n",
      "[epoch 17] Completed in 0:01:49\n",
      "[epoch 17] [epoch 17] Test set: avg. loss: 5.274  (perplexity: 195.20)\n",
      "\n",
      "[epoch 18] Starting epoch 18\n",
      "[batch 286]: seen 287000 words at 9553 wps, loss = 3.986\n",
      "[batch 568]: seen 569000 words at 9471 wps, loss = 3.988\n",
      "[batch 852]: seen 853000 words at 9459 wps, loss = 3.984\n",
      "[epoch 18] Completed in 0:01:47\n",
      "[epoch 18] [epoch 18] Test set: avg. loss: 5.263  (perplexity: 193.00)\n",
      "\n",
      "[epoch 19] Starting epoch 19\n",
      "[batch 282]: seen 283000 words at 9425 wps, loss = 3.972\n",
      "[batch 567]: seen 568000 words at 9449 wps, loss = 3.974\n",
      "[batch 848]: seen 849000 words at 9417 wps, loss = 3.972\n",
      "[epoch 19] Completed in 0:01:48\n",
      "[epoch 19] [epoch 19] Test set: avg. loss: 5.252  (perplexity: 190.96)\n",
      "\n",
      "[epoch 20] Starting epoch 20\n",
      "[batch 274]: seen 275000 words at 9154 wps, loss = 3.964\n",
      "[batch 546]: seen 547000 words at 9101 wps, loss = 3.965\n",
      "[batch 816]: seen 817000 words at 9066 wps, loss = 3.963\n",
      "[epoch 20] Completed in 0:01:51\n",
      "[epoch 20] [epoch 20] Test set: avg. loss: 5.244  (perplexity: 189.39)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Will print status every this many seconds\n",
    "print_interval = 5\n",
    "\n",
    "# Clear old log directory\n",
    "shutil.rmtree(\"tf_summaries\", ignore_errors=True)\n",
    "\n",
    "lm = rnnlm.RNNLM(**model_params)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "\n",
    "# Explicitly add global initializer and variable saver to LM graph\n",
    "with lm.graph.as_default():\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "# Clear old log directory\n",
    "shutil.rmtree(TF_SAVEDIR, ignore_errors=True)\n",
    "if not os.path.isdir(TF_SAVEDIR):\n",
    "    os.makedirs(TF_SAVEDIR)\n",
    "\n",
    "with tf.Session(graph=lm.graph) as session:\n",
    "    # Seed RNG for repeatability\n",
    "    tf.set_random_seed(42)\n",
    "\n",
    "    session.run(initializer)\n",
    "\n",
    "    for epoch in xrange(1,num_epochs+1):\n",
    "        t0_epoch = time.time()\n",
    "        bi = utils.batch_generator(train_ids, batch_size, max_time)\n",
    "        print \"[epoch %d] Starting epoch %d\" % (epoch, epoch)\n",
    "        #### YOUR CODE HERE ####\n",
    "        # Run a training epoch.\n",
    "        run_epoch(lm, session, bi,\n",
    "              train=True, verbose=True,\n",
    "              tick_s=30, learning_rate=learning_rate)\n",
    "        \n",
    "        #### END(YOUR CODE) ####\n",
    "        print \"[epoch %d] Completed in %s\" % (epoch, utils.pretty_timedelta(since=t0_epoch))\n",
    "    \n",
    "        # Save a checkpoint\n",
    "        saver.save(session, checkpoint_filename, global_step=epoch)\n",
    "    \n",
    "        ##\n",
    "        # score_dataset will run a forward pass over the entire dataset\n",
    "        # and report perplexity scores. This can be slow (around 1/2 to \n",
    "        # 1/4 as long as a full epoch), so you may want to comment it out\n",
    "        # to speed up training on a slow machine. Be sure to run it at the \n",
    "        # end to evaluate your score.\n",
    "        print (\"[epoch %d]\" % epoch),\n",
    "        #score_dataset(lm, session, train_ids, name=\"Train set\")\n",
    "        print (\"[epoch %d]\" % epoch),\n",
    "        score_dataset(lm, session, test_ids, name=\"Test set\")\n",
    "        print \"\"\n",
    "    \n",
    "    # Save final model\n",
    "    saver.save(session, trained_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Sampling Sentences (5 points)\n",
    "\n",
    "If you didn't already in **part (b)**, implement the `BuildSamplerGraph()` method in `rnnlm.py` See the function docstring for more information.\n",
    "\n",
    "#### Implement the `sample_step()` method below (5 points)\n",
    "This should access the Tensors you create in `BuildSamplerGraph()`. Given an input batch and initial states, it should return a vector of shape `[batch_size,1]` containing sampled indices for the next word of each batch sequence.\n",
    "\n",
    "Run the method using the provided code to generate 10 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_step(lm, session, input_w, initial_h):\n",
    "    \"\"\"Run a single RNN step and return sampled predictions.\n",
    "  \n",
    "    Args:\n",
    "      lm : rnnlm.RNNLM\n",
    "      session: tf.Session\n",
    "      input_w : [batch_size] vector of indices\n",
    "      initial_h : [batch_size, hidden_dims] initial state\n",
    "    \n",
    "    Returns:\n",
    "      final_h : final hidden state, compatible with initial_h\n",
    "      samples : [batch_size, 1] vector of indices\n",
    "    \"\"\"\n",
    "    # Reshape input to column vector\n",
    "    input_w = np.array(input_w, dtype=np.int32).reshape([-1,1])\n",
    "  \n",
    "    #### YOUR CODE HERE ####\n",
    "    # Run sample ops\n",
    "    feed_dict = { lm.initial_h_ : initial_h, lm.input_w_ : input_w }\n",
    "    samples, final_h = session.run([lm.pred_samples_, lm.final_h_], feed_dict)\n",
    "\n",
    "    #### END(YOUR CODE) ####\n",
    "    # Note indexing here: \n",
    "    #   [batch_size, max_time, 1] -> [batch_size, 1]\n",
    "    return final_h, samples[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf_saved/rnnlm_trained\n",
      "<s> the doctor few to frequency impossible with ideal -- which questions or antibodies in new birth or <unk> , but \n",
      "<s> the man of his possible to gown the only of the shaken <unk> within <unk> fashionable to their unity , \n",
      "<s> they <unk> males in less planted , her business , <unk> <unk> , but the shirt time of the appendix \n",
      "<s> we had be good after the of nitrogen . </s> <s> \n",
      "<s> in an violently , my absurd <unk> speak and he am through the presence <unk> teachers . </s> <s> \n",
      "<s> the lincoln of eugene shall undoubtedly contract invariably the glasses <unk> , and the american of the <unk> of new \n",
      "<s> <unk> adoption , and for her undue of the whole of its entire hansen that most <unk> , or to \n",
      "<s> it has out the whether of his own total and people by tend by the appreciation , they will painter \n",
      "<s> a `` pan belt '' , he would gone such one of <unk> in present the state became street , \n",
      "<s> phil sure longer and her said kind , mr. in winter . </s> <s> \n"
     ]
    }
   ],
   "source": [
    "# Same as above, but as a batch\n",
    "max_steps = 20\n",
    "num_samples = 10\n",
    "random_seed = 42\n",
    "\n",
    "lm = rnnlm.RNNLM(**model_params)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildSamplerGraph()\n",
    "\n",
    "with lm.graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=lm.graph) as session:\n",
    "    # Seed RNG for repeatability\n",
    "    tf.set_random_seed(random_seed)\n",
    "    \n",
    "    # Load the trained model\n",
    "    saver.restore(session, trained_filename)\n",
    "\n",
    "    # Make initial state for a batch with batch_size = num_samples\n",
    "    w = np.repeat([[vocab.START_ID]], num_samples, axis=0)\n",
    "    h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "    # We'll take one step for each sequence on each iteration \n",
    "    for i in xrange(max_steps):\n",
    "        h, y = sample_step(lm, session, w[:,-1:], h)\n",
    "        w = np.hstack((w,y))\n",
    "\n",
    "    # Print generated sentences\n",
    "    for row in w:\n",
    "        for i, word_id in enumerate(row):\n",
    "            print vocab.id_to_word[word_id],\n",
    "            if (i != 0) and (word_id == vocab.START_ID):\n",
    "                break\n",
    "        print \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## (e) Linguistic Properties (5 points)\n",
    "\n",
    "Now that we've trained our RNNLM, let's test a few properties of the model to see how well it learns linguistic phenomena. We'll do this with a scoring task: given two or more test sentences, our model should score the more plausible (or more correct) sentence with a higher log-probability.\n",
    "\n",
    "We'll define a scoring function to help us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_seq(lm, session, seq, vocab):\n",
    "    \"\"\"Score a sequence of words. Returns total log-probability.\"\"\"\n",
    "    padded_ids = vocab.words_to_ids(utils.canonicalize_words([\"<s>\"] + seq + [\"</s>\"], \n",
    "                                                             wordset=vocab.word_to_id))\n",
    "    w = np.reshape(padded_ids[:-1], [1,-1])\n",
    "    y = np.reshape(padded_ids[1:],  [1,-1])\n",
    "    h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "    feed_dict = {lm.input_w_:w,\n",
    "                 lm.target_y_:y,\n",
    "                 lm.initial_h_:h,\n",
    "                 lm.dropout_keep_prob_: 1.0}\n",
    "    # Return log(P(seq)) = -1*loss\n",
    "    return -1*session.run(lm.loss_, feed_dict)\n",
    "\n",
    "def load_and_score(inputs, sort=False):\n",
    "    \"\"\"Load the trained model and score the given words.\"\"\"\n",
    "    lm = rnnlm.RNNLM(**model_params)\n",
    "    lm.BuildCoreGraph()\n",
    "    \n",
    "    with lm.graph.as_default():\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session(graph=lm.graph) as session:  \n",
    "        # Load the trained model\n",
    "        saver.restore(session, trained_filename)\n",
    "\n",
    "        if isinstance(inputs[0], str) or isinstance(inputs[0], unicode):\n",
    "            inputs = [inputs]\n",
    "\n",
    "        # Actually run scoring\n",
    "        results = []\n",
    "        for words in inputs:\n",
    "            score = score_seq(lm, session, words, vocab)\n",
    "            results.append((score, words))\n",
    "\n",
    "        # Sort if requested\n",
    "        if sort: results = sorted(results, reverse=True)\n",
    "\n",
    "        # Print results\n",
    "        for score, words in results:\n",
    "            print \"\\\"%s\\\" : %.02f\" % (\" \".join(words), score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf_saved/rnnlm_trained\n",
      "\"once upon a time\" : -5.91\n",
      "\"the quick brown fox jumps over the lazy dog\" : -6.93\n"
     ]
    }
   ],
   "source": [
    "sents = [\"once upon a time\",\n",
    "         \"the quick brown fox jumps over the lazy dog\"]\n",
    "load_and_score([s.split() for s in sents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Number agreement\n",
    "\n",
    "Compare **\"the boy and the girl [are/is]\"**. Which is more plausible according to your model?\n",
    "\n",
    "If your model doesn't order them correctly (*this is OK*), why do you think that might be? (answer in cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf_saved/rnnlm_trained\n",
      "\"the boy and the girl are\" : -5.06\n",
      "\"the boy and the girl is\" : -4.87\n",
      "\"the boy and the girls are\" : -5.23\n",
      "\"the boy and the girls is\" : -5.03\n",
      "\"the girl and the boys are\" : -5.28\n",
      "\"the girl and the boys is\" : -5.09\n",
      "\"the boys are\" : -5.77\n",
      "\"the boys is\" : -5.37\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "sents = [\"the boy and the girl are\",\n",
    "         \"the boy and the girl is\",\n",
    "         \"the boy and the girls are\",\n",
    "         \"the boy and the girls is\",\n",
    "         \"the girl and the boys are\",\n",
    "         \"the girl and the boys is\",\n",
    "         \"the boys are\",\n",
    "          \"the boys is\", ]\n",
    "load_and_score([s.split() for s in sents])\n",
    "#### END(YOUR CODE) ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer to part 1. question(s)\n",
    "\n",
    "*For the given examples, there are cases where \"and the girl is\" is valid.  For example, if the \"and\" is connecting what could be two independent sentences that the author choose to join into one with \"and\" as the connector.  More perplexing is that the model prefers \"is\" over \"are\" when the preceding word is plural, even without the \"and\".  Perhaps, even with a hidden state size of 200, the model wasn't able to capture number agreement, or there weren't enough examples of cases with \"is\" and \"are\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Type/semantic agreement\n",
    "\n",
    "Compare:\n",
    "- **\"peanuts are my favorite kind of [nut/vegetable]\"**\n",
    "- **\"when I'm hungry I really prefer to [eat/drink]\"**\n",
    "\n",
    "Of each pair, which is more plausible according to your model?\n",
    "\n",
    "How would you expect a 3-gram language model to perform at this example? How about a 5-gram model? (answer in cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf_saved/rnnlm_trained\n",
      "\"peanuts are my favorite kind of nut\" : -6.43\n",
      "\"peanuts are my favorite kind of vegetable\" : -6.51\n",
      "\"when I'm hungry I really prefer to eat\" : -7.21\n",
      "\"when I'm hungry I really prefer to drink\" : -7.32\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "sents = [\"peanuts are my favorite kind of nut\",\n",
    "         \"peanuts are my favorite kind of vegetable\",\n",
    "         \"when I'm hungry I really prefer to eat\",\n",
    "         \"when I'm hungry I really prefer to drink\",]\n",
    "load_and_score([s.split() for s in sents])\n",
    "\n",
    "\n",
    "#### END(YOUR CODE) ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer to part 2. question(s)\n",
    "\n",
    "*For the peanut example, neither a 3-gram or 5-gram model have a large enough window to be able to select the correct response for the last word.  Both models would be just as likely to choose \"book\" or \"movie\" as the selection.  For the hunger eample, the 5-gram model would have just large enough of a window to see both \"hungry\" and \"eat/drink\" to distinguish between the two.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Adjective ordering (just for fun)\n",
    "\n",
    "Let's repeat the exercise from Week 2:\n",
    "\n",
    "![Adjective Order](adjective_order.jpg)\n",
    "*source: https://twitter.com/MattAndersonBBC/status/772002757222002688?lang=en*\n",
    "\n",
    "We'll consider a toy example (literally), and consider all possible adjective permutations.\n",
    "\n",
    "Note that this is somewhat sensitive to training, and even a good language model might not get it all correct. Why might the NN fail, if the trigram model from Week 2 was able to solve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf_saved/rnnlm_trained\n",
      "\"I have lots of plastic square green toys\" : -7.73\n",
      "\"I have lots of plastic green square toys\" : -7.74\n",
      "\"I have lots of green plastic square toys\" : -7.76\n",
      "\"I have lots of green square plastic toys\" : -7.77\n",
      "\"I have lots of square plastic green toys\" : -7.86\n",
      "\"I have lots of square green plastic toys\" : -7.87\n"
     ]
    }
   ],
   "source": [
    "prefix = \"I have lots of\".split()\n",
    "noun = \"toys\"\n",
    "adjectives = [\"square\", \"green\", \"plastic\"]\n",
    "inputs = []\n",
    "for adjs in itertools.permutations(adjectives):\n",
    "    words = prefix + list(adjs) + [noun]\n",
    "    inputs.append(words)\n",
    "    \n",
    "load_and_score(inputs, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer to part 3. question(s)\n",
    "\n",
    "*In this case, the model gets it completely wrong.  An earlier version of the NN model did get it correct.  This shows how sensitive this case is.  The hidden state might not be large enough to capture the nuances of this case.  The n-gram models would be able perform better if it had seen examples in the corpus of \"square green\" and \"green plastic\".  Then it would be able to choose the correct order.  Though sparsity is an issue.  It would take an enormous corpus to capture all the combinations of all of the different possible adjectives.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
